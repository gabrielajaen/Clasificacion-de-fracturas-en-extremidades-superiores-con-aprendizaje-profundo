{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e5e8d3b-e689-4870-a3e8-aeabf38b21fb",
   "metadata": {},
   "source": [
    "**CONTAR CANTIDAD IMAGENES EN MURAV2.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce56b22a-8f5e-41c6-9b26-826c4e1edc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ TRAIN Dataset\n",
      "   XR_FOREARM: 1825 im√°genes\n",
      "   XR_WRIST: 9752 im√°genes\n",
      "   XR_ELBOW: 4931 im√°genes\n",
      "   XR_SHOULDER: 8379 im√°genes\n",
      "   XR_HUMERUS: 1272 im√°genes\n",
      "   XR_HAND: 5543 im√°genes\n",
      "   XR_FINGER: 5106 im√°genes\n",
      "\n",
      "üìÇ VALID Dataset\n",
      "   XR_FOREARM: 301 im√°genes\n",
      "   XR_FINGER: 461 im√°genes\n",
      "   XR_SHOULDER: 563 im√°genes\n",
      "   XR_HAND: 460 im√°genes\n",
      "   XR_HUMERUS: 288 im√°genes\n",
      "   XR_ELBOW: 465 im√°genes\n",
      "   XR_WRIST: 659 im√°genes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ruta de la carpeta de datos\n",
    "base_drive_path = \"G:/Mi unidad/TESIS/\"  # Asegurar que esta ruta es correcta\n",
    "data_directory = os.path.join(base_drive_path, \"MURA_v2.1\")\n",
    "\n",
    "def count_images_per_category(directory):\n",
    "    category_counts = {}\n",
    "\n",
    "    for split in [\"train\", \"valid\"]:\n",
    "        split_path = os.path.join(directory, split)\n",
    "        if not os.path.exists(split_path):\n",
    "            print(f\"‚ö†Ô∏è No se encontr√≥ la carpeta: {split_path}\")\n",
    "            continue\n",
    "\n",
    "        category_counts[split] = {}\n",
    "        for category in os.listdir(split_path):\n",
    "            category_path = os.path.join(split_path, category)\n",
    "            if os.path.isdir(category_path):\n",
    "                total_images = 0\n",
    "                for root, _, files in os.walk(category_path):  # Recorre todas las subcarpetas\n",
    "                    total_images += sum(1 for file in files if file.endswith(('.png', '.jpg', '.jpeg')))\n",
    "                category_counts[split][category] = total_images\n",
    "\n",
    "    return category_counts\n",
    "\n",
    "# Contar im√°genes en train y valid\n",
    "category_image_counts = count_images_per_category(data_directory)\n",
    "\n",
    "# Mostrar resultados\n",
    "for split, categories in category_image_counts.items():\n",
    "    print(f\"\\nüìÇ {split.upper()} Dataset\")\n",
    "    for category, count in categories.items():\n",
    "        print(f\"   {category}: {count} im√°genes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e31ba3-84c8-48cf-a2b3-75c34ff68151",
   "metadata": {},
   "source": [
    "**APLICACION DE CLAHE Y UNSHARP MASK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3e58744-a391-44a4-b0bf-1f7498f8d0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iniciando el procesamiento de im√°genes...\n",
      " Procesando 40009 im√°genes con 8 hilos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando im√°genes:   0%|                                                                  | 0/40009 [00:00<?, ?img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No se pudo cargar: G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image3.png - Error: Could not find a backend to open `G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image3.png`` with iomode `r`.\n",
      "Based on the extension, the following plugins might add capable backends:\n",
      "  pyav:  pip install imageio[pyav]\n",
      "‚ùå No se pudo cargar: G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study1_negative\\._image1.png - Error: Could not find a backend to open `G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study1_negative\\._image1.png`` with iomode `r`.\n",
      "Based on the extension, the following plugins might add capable backends:\n",
      "  pyav:  pip install imageio[pyav]\n",
      "‚ùå No se pudo cargar: G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image1.png - Error: Could not find a backend to open `G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image1.png`` with iomode `r`.\n",
      "Based on the extension, the following plugins might add capable backends:\n",
      "  pyav:  pip install imageio[pyav]\n",
      "‚ùå No se pudo cargar: G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image2.png - Error: Could not find a backend to open `G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image2.png`` with iomode `r`.\n",
      "Based on the extension, the following plugins might add capable backends:\n",
      "  pyav:  pip install imageio[pyav]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SKACE\\AppData\\Local\\Temp\\ipykernel_11716\\3870136753.py:44: UserWarning: G:/Mi unidad/TESIS\\MURA_UC\\train\\XR_HAND\\patient10593\\study1_negative\\image2.png is a low contrast image\n",
      "  io.imsave(save_path, (enhanced_image * 255).astype(np.uint8))\n",
      "C:\\Users\\SKACE\\AppData\\Local\\Temp\\ipykernel_11716\\3870136753.py:44: UserWarning: G:/Mi unidad/TESIS\\MURA_UC\\train\\XR_FINGER\\patient04687\\study1_negative\\image2.png is a low contrast image\n",
      "  io.imsave(save_path, (enhanced_image * 255).astype(np.uint8))\n",
      "Procesando im√°genes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40009/40009 [11:37<00:00, 57.33img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Procesamiento completado en 697.92 segundos.\n",
      " Total de im√°genes procesadas: 40005\n",
      " Total de im√°genes fallidas: 4\n",
      "‚ùå Im√°genes corruptas que no fueron agregadas:\n",
      "G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study1_negative\\._image1.png\n",
      "G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image2.png\n",
      "G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image3.png\n",
      "G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image1.png\n",
      " Procesamiento completado!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from skimage import io, color, exposure, transform\n",
    "from skimage.filters import unsharp_mask\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Ajustar la ruta de Google Drive en Windows\n",
    "base_drive_path = \"G:/Mi unidad/TESIS\"  # Asegurar que esta ruta es correcta en tu sistema\n",
    "\n",
    "def apply_unsharp_mask(image, radius=3, amount=3):\n",
    "    \"\"\" Aplica Unsharp Mask usando skimage para mejorar la nitidez \"\"\"\n",
    "    return unsharp_mask(image, radius=radius, amount=amount)\n",
    "\n",
    "def apply_clahe(image, clip_limit=0.03):\n",
    "    \"\"\" Aplica CLAHE usando skimage para mejorar el contraste \"\"\"\n",
    "    return exposure.equalize_adapthist(image, clip_limit=clip_limit)\n",
    "\n",
    "def process_image(img_path, save_path):\n",
    "    \"\"\" Carga, mejora y guarda una imagen v√°lida \"\"\"\n",
    "    try:\n",
    "        image = io.imread(img_path)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå No se pudo cargar: {img_path} - Error: {e}\")\n",
    "        return False\n",
    "    \n",
    "    if image is None or image.size == 0:\n",
    "        print(f\"‚ùå Imagen corrupta o vac√≠a: {img_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Convertir a escala de grises si es RGB\n",
    "    if len(image.shape) == 3:\n",
    "        image = color.rgb2gray(image)\n",
    "\n",
    "    # Redimensionar la imagen \n",
    "    image = transform.resize(image, (384, 384), anti_aliasing=True)\n",
    "\n",
    "    # Aplicar filtros\n",
    "    enhanced_image = apply_unsharp_mask(image)\n",
    "    enhanced_image = apply_clahe(enhanced_image)\n",
    "\n",
    "    # Guardar imagen mejorada\n",
    "    io.imsave(save_path, (enhanced_image * 255).astype(np.uint8))\n",
    "    return True\n",
    "\n",
    "def process_images_parallel(input_folder, output_folder, num_workers=8):\n",
    "    \"\"\" Procesa im√°genes en paralelo recorriendo todas las subcarpetas, excluyendo im√°genes corruptas \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    image_paths = []\n",
    "    failed_images = []\n",
    "    \n",
    "    # Recorrer todas las subcarpetas para encontrar im√°genes\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                relative_path = os.path.relpath(root, input_folder)\n",
    "                save_path = os.path.join(output_folder, relative_path)\n",
    "                os.makedirs(save_path, exist_ok=True)\n",
    "                image_paths.append((os.path.join(root, file), os.path.join(save_path, file)))\n",
    "\n",
    "    if not image_paths:\n",
    "        print(\"‚ö†Ô∏è No se encontraron im√°genes. Verifica la estructura de MURA-v1.1.\")\n",
    "        return\n",
    "\n",
    "    # Procesamiento en paralelo\n",
    "    start_time = time.time()\n",
    "    print(f\" Procesando {len(image_paths)} im√°genes con {num_workers} hilos...\")\n",
    "\n",
    "    with tqdm(total=len(image_paths), desc=\"Procesando im√°genes\", unit=\"img\", dynamic_ncols=True) as pbar:\n",
    "        with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "            results = list(executor.map(lambda p: process_image(*p), image_paths))\n",
    "            pbar.update(len(results))\n",
    "\n",
    "    # Registrar im√°genes fallidas\n",
    "    failed_images = [image_paths[i][0] for i, success in enumerate(results) if not success]\n",
    "    print(f\"\\n Procesamiento completado en {time.time() - start_time:.2f} segundos.\")\n",
    "    print(f\" Total de im√°genes procesadas: {len(image_paths) - len(failed_images)}\")\n",
    "    print(f\" Total de im√°genes fallidas: {len(failed_images)}\")\n",
    "    \n",
    "    if failed_images:\n",
    "        print(\"‚ùå Im√°genes corruptas que no fueron agregadas:\")\n",
    "        for img in failed_images:\n",
    "            print(img)\n",
    "\n",
    "# Directorios de entrada y salida en Google Drive en Windows\n",
    "input_directory = os.path.join(base_drive_path, \"MURA-v1.1\")\n",
    "output_directory = os.path.join(base_drive_path, \"MURA_UC\")  # Nueva carpeta para guardar im√°genes procesadas\n",
    "\n",
    "# Procesar im√°genes en paralelo con 8 hilos\n",
    "tqdm.write(\" Iniciando el procesamiento de im√°genes...\")\n",
    "process_images_parallel(input_directory, output_directory, num_workers=8)\n",
    "tqdm.write(\" Procesamiento completado!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a7b023-9215-40c8-a5a8-4a5f92a698ad",
   "metadata": {},
   "source": [
    "**DIVIDIR 80 Y 20% DATOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c4fa77-3f1b-4983-9cf7-e11bfda185f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Divisi√≥n completada. CSVs generados en G:/Mi unidad/TESIS/MURA_UCD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Ruta del dataset original (usaremos tanto train como valid)\n",
    "ruta_base = \"G:/Mi unidad/TESIS/MURA_UC\"\n",
    "ruta_original_train = os.path.join(ruta_base, \"train\")\n",
    "ruta_original_valid = os.path.join(ruta_base, \"valid\")  # Se incluir√° en la divisi√≥n\n",
    "\n",
    "# Nueva carpeta donde se almacenar√° la divisi√≥n\n",
    "ruta_nueva_base = \"G:/Mi unidad/TESIS/MURA_UCD\"\n",
    "ruta_nueva_train = os.path.join(ruta_nueva_base, \"train\")\n",
    "ruta_nueva_valid = os.path.join(ruta_nueva_base, \"valid\")\n",
    "\n",
    "# Crear las nuevas carpetas si no existen\n",
    "os.makedirs(ruta_nueva_train, exist_ok=True)\n",
    "os.makedirs(ruta_nueva_valid, exist_ok=True)\n",
    "\n",
    "# Listas para almacenar las rutas y etiquetas\n",
    "datos = []  # Lista general para las im√°genes\n",
    "\n",
    "# Funci√≥n para recopilar im√°genes de ambas carpetas\n",
    "def recopilar_imagenes(ruta_base):\n",
    "    imagenes = []\n",
    "    if os.path.isdir(ruta_base):\n",
    "        for tipo in os.listdir(ruta_base):  # Recorrer XR_ELBOW, XR_FINGER, etc.\n",
    "            ruta_tipo = os.path.join(ruta_base, tipo)\n",
    "            if os.path.isdir(ruta_tipo):\n",
    "                for paciente in os.listdir(ruta_tipo):  # Recorrer patient0001, patient0002, etc.\n",
    "                    ruta_paciente = os.path.join(ruta_tipo, paciente)\n",
    "                    if os.path.isdir(ruta_paciente):\n",
    "                        for estudio in os.listdir(ruta_paciente):  # Recorrer study1_negative, study2_positive, etc.\n",
    "                            ruta_estudio = os.path.join(ruta_paciente, estudio)\n",
    "                            if os.path.isdir(ruta_estudio):\n",
    "                                for img in os.listdir(ruta_estudio):  # Listar im√°genes\n",
    "                                    img_path = os.path.join(ruta_estudio, img)\n",
    "                                    etiqueta = 0 if \"negative\" in estudio.lower() else 1  # Etiqueta 0 o 1\n",
    "                                    imagenes.append((img_path, etiqueta, tipo, paciente, estudio))\n",
    "    return imagenes\n",
    "\n",
    "# Recopilar im√°genes de ambas carpetas\n",
    "imagenes_total = recopilar_imagenes(ruta_original_train) + recopilar_imagenes(ruta_original_valid)\n",
    "\n",
    "# Mezclar im√°genes aleatoriamente\n",
    "random.shuffle(imagenes_total)\n",
    "\n",
    "# Calcular la cantidad exacta para train y valid\n",
    "num_train = int(len(imagenes_total) * 0.8)\n",
    "imagenes_train = imagenes_total[:num_train]\n",
    "imagenes_valid = imagenes_total[num_train:]\n",
    "\n",
    "# Copiar im√°genes y crear CSV\n",
    "datos_train, datos_valid = [], []\n",
    "\n",
    "for img_path, etiqueta, tipo, paciente, estudio in imagenes_train:\n",
    "    ruta_tipo_train = os.path.join(ruta_nueva_train, tipo)\n",
    "    ruta_paciente_train = os.path.join(ruta_tipo_train, paciente)\n",
    "    ruta_estudio_train = os.path.join(ruta_paciente_train, estudio)\n",
    "    os.makedirs(ruta_estudio_train, exist_ok=True)\n",
    "    nueva_ruta = os.path.join(ruta_estudio_train, os.path.basename(img_path))\n",
    "\n",
    "    try:\n",
    "        shutil.copy(img_path, nueva_ruta)\n",
    "        datos_train.append([nueva_ruta, etiqueta])\n",
    "    except Exception as e:\n",
    "        print(f\"Error al copiar {img_path}: {e}\")\n",
    "\n",
    "for img_path, etiqueta, tipo, paciente, estudio in imagenes_valid:\n",
    "    ruta_tipo_valid = os.path.join(ruta_nueva_valid, tipo)\n",
    "    ruta_paciente_valid = os.path.join(ruta_tipo_valid, paciente)\n",
    "    ruta_estudio_valid = os.path.join(ruta_paciente_valid, estudio)\n",
    "    os.makedirs(ruta_estudio_valid, exist_ok=True)\n",
    "    nueva_ruta = os.path.join(ruta_estudio_valid, os.path.basename(img_path))\n",
    "\n",
    "    try:\n",
    "        shutil.copy(img_path, nueva_ruta)\n",
    "        datos_valid.append([nueva_ruta, etiqueta])\n",
    "    except Exception as e:\n",
    "        print(f\"Error al copiar {img_path}: {e}\")\n",
    "\n",
    "# Guardar los CSV\n",
    "df_train = pd.DataFrame(datos_train, columns=[\"ruta\", \"etiqueta\"])\n",
    "df_valid = pd.DataFrame(datos_valid, columns=[\"ruta\", \"etiqueta\"])\n",
    "\n",
    "df_train.to_csv(os.path.join(ruta_nueva_base, \"train.csv\"), index=False)\n",
    "df_valid.to_csv(os.path.join(ruta_nueva_base, \"valid.csv\"), index=False)\n",
    "\n",
    "print(f\"‚úÖ Divisi√≥n completada. CSVs generados en {ruta_nueva_base}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52249676-53c3-4ec3-a950-a733cc00e935",
   "metadata": {},
   "source": [
    "**CONTAR CANRIDAD DE IMAGENES DESPUES DE DIVISION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32767009-f0b6-484f-9be0-89de74441c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de im√°genes en TRAIN: 32004\n",
      "Total de im√°genes en VALID: 8001\n",
      "Total de im√°genes en el dataset dividido: 40005\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ruta a la carpeta nueva donde se dividieron las im√°genes\n",
    "ruta_nueva_base = \"G:/Mi unidad/TESIS/MURA_UCD\"\n",
    "ruta_train = os.path.join(ruta_nueva_base, \"train\")\n",
    "ruta_valid = os.path.join(ruta_nueva_base, \"valid\")\n",
    "\n",
    "# Funci√≥n para contar im√°genes en una carpeta\n",
    "def contar_imagenes(ruta_base):\n",
    "    total_imagenes = 0\n",
    "    for tipo in os.listdir(ruta_base):  # Recorrer XR_ELBOW, XR_FINGER, etc.\n",
    "        ruta_tipo = os.path.join(ruta_base, tipo)\n",
    "        if os.path.isdir(ruta_tipo):\n",
    "            for paciente in os.listdir(ruta_tipo):  # Recorrer patient0001, patient0002, etc.\n",
    "                ruta_paciente = os.path.join(ruta_tipo, paciente)\n",
    "                if os.path.isdir(ruta_paciente):\n",
    "                    for estudio in os.listdir(ruta_paciente):  # Recorrer study1_negative, study2_positive, etc.\n",
    "                        ruta_estudio = os.path.join(ruta_paciente, estudio)\n",
    "                        if os.path.isdir(ruta_estudio):\n",
    "                            total_imagenes += len(os.listdir(ruta_estudio))  # Contar archivos en cada estudio\n",
    "    return total_imagenes\n",
    "\n",
    "# Contar im√°genes en train y valid\n",
    "total_train = contar_imagenes(ruta_train)\n",
    "total_valid = contar_imagenes(ruta_valid)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Total de im√°genes en TRAIN: {total_train}\")\n",
    "print(f\"Total de im√°genes en VALID: {total_valid}\")\n",
    "\n",
    "# Verificar que la suma sea 40,005\n",
    "total_general = total_train + total_valid\n",
    "print(f\"Total de im√°genes en el dataset dividido: {total_general}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698e2e4-b2e6-4149-b214-dbfa1750007b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
