{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "97e31ba3-84c8-48cf-a2b3-75c34ff68151",
      "metadata": {
        "id": "97e31ba3-84c8-48cf-a2b3-75c34ff68151"
      },
      "source": [
        "**APLICACION DE CLAHE Y UNSHARP MASK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3e58744-a391-44a4-b0bf-1f7498f8d0bb",
      "metadata": {
        "id": "e3e58744-a391-44a4-b0bf-1f7498f8d0bb",
        "outputId": "75c1efa6-e9fd-4d90-ab98-94e8c5b10075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Iniciando el procesamiento de imágenes...\n",
            " Procesando 40009 imágenes con 8 hilos...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Procesando imágenes:   0%|                                                                  | 0/40009 [00:00<?, ?img/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ No se pudo cargar: G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image3.png - Error: Could not find a backend to open `G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image3.png`` with iomode `r`.\n",
            "Based on the extension, the following plugins might add capable backends:\n",
            "  pyav:  pip install imageio[pyav]\n",
            "❌ No se pudo cargar: G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study1_negative\\._image1.png - Error: Could not find a backend to open `G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study1_negative\\._image1.png`` with iomode `r`.\n",
            "Based on the extension, the following plugins might add capable backends:\n",
            "  pyav:  pip install imageio[pyav]\n",
            "❌ No se pudo cargar: G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image1.png - Error: Could not find a backend to open `G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image1.png`` with iomode `r`.\n",
            "Based on the extension, the following plugins might add capable backends:\n",
            "  pyav:  pip install imageio[pyav]\n",
            "❌ No se pudo cargar: G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image2.png - Error: Could not find a backend to open `G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image2.png`` with iomode `r`.\n",
            "Based on the extension, the following plugins might add capable backends:\n",
            "  pyav:  pip install imageio[pyav]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\SKACE\\AppData\\Local\\Temp\\ipykernel_11716\\3870136753.py:44: UserWarning: G:/Mi unidad/TESIS\\MURA_UC\\train\\XR_HAND\\patient10593\\study1_negative\\image2.png is a low contrast image\n",
            "  io.imsave(save_path, (enhanced_image * 255).astype(np.uint8))\n",
            "C:\\Users\\SKACE\\AppData\\Local\\Temp\\ipykernel_11716\\3870136753.py:44: UserWarning: G:/Mi unidad/TESIS\\MURA_UC\\train\\XR_FINGER\\patient04687\\study1_negative\\image2.png is a low contrast image\n",
            "  io.imsave(save_path, (enhanced_image * 255).astype(np.uint8))\n",
            "Procesando imágenes: 100%|██████████████████████████████████████████████████████| 40009/40009 [11:37<00:00, 57.33img/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Procesamiento completado en 697.92 segundos.\n",
            " Total de imágenes procesadas: 40005\n",
            " Total de imágenes fallidas: 4\n",
            "❌ Imágenes corruptas que no fueron agregadas:\n",
            "G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study1_negative\\._image1.png\n",
            "G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image2.png\n",
            "G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image3.png\n",
            "G:/Mi unidad/TESIS\\MURA-v1.1\\train\\XR_WRIST\\patient07840\\study2_negative\\._image1.png\n",
            " Procesamiento completado!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "from skimage import io, color, exposure, transform\n",
        "from skimage.filters import unsharp_mask\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Ajustar la ruta de Google Drive en Windows\n",
        "base_drive_path = \"G:/Mi unidad/TESIS\"  # Asegurar que esta ruta es correcta en tu sistema\n",
        "\n",
        "def apply_unsharp_mask(image, radius=3, amount=3):\n",
        "    \"\"\" Aplica Unsharp Mask usando skimage para mejorar la nitidez \"\"\"\n",
        "    return unsharp_mask(image, radius=radius, amount=amount)\n",
        "\n",
        "def apply_clahe(image, clip_limit=0.03):\n",
        "    \"\"\" Aplica CLAHE usando skimage para mejorar el contraste \"\"\"\n",
        "    return exposure.equalize_adapthist(image, clip_limit=clip_limit)\n",
        "\n",
        "def process_image(img_path, save_path):\n",
        "    \"\"\" Carga, mejora y guarda una imagen válida \"\"\"\n",
        "    try:\n",
        "        image = io.imread(img_path)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ No se pudo cargar: {img_path} - Error: {e}\")\n",
        "        return False\n",
        "\n",
        "    if image is None or image.size == 0:\n",
        "        print(f\"❌ Imagen corrupta o vacía: {img_path}\")\n",
        "        return False\n",
        "\n",
        "    # Convertir a escala de grises si es RGB\n",
        "    if len(image.shape) == 3:\n",
        "        image = color.rgb2gray(image)\n",
        "\n",
        "    # Redimensionar la imagen\n",
        "    image = transform.resize(image, (384, 384), anti_aliasing=True)\n",
        "\n",
        "    # Aplicar filtros\n",
        "    enhanced_image = apply_unsharp_mask(image)\n",
        "    enhanced_image = apply_clahe(enhanced_image)\n",
        "\n",
        "    # Guardar imagen mejorada\n",
        "    io.imsave(save_path, (enhanced_image * 255).astype(np.uint8))\n",
        "    return True\n",
        "\n",
        "def process_images_parallel(input_folder, output_folder, num_workers=8):\n",
        "    \"\"\" Procesa imágenes en paralelo recorriendo todas las subcarpetas, excluyendo imágenes corruptas \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    image_paths = []\n",
        "    failed_images = []\n",
        "\n",
        "    # Recorrer todas las subcarpetas para encontrar imágenes\n",
        "    for root, _, files in os.walk(input_folder):\n",
        "        for file in files:\n",
        "            if file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                relative_path = os.path.relpath(root, input_folder)\n",
        "                save_path = os.path.join(output_folder, relative_path)\n",
        "                os.makedirs(save_path, exist_ok=True)\n",
        "                image_paths.append((os.path.join(root, file), os.path.join(save_path, file)))\n",
        "\n",
        "    if not image_paths:\n",
        "        print(\"⚠️ No se encontraron imágenes. Verifica la estructura de MURA-v1.1.\")\n",
        "        return\n",
        "\n",
        "    # Procesamiento en paralelo\n",
        "    start_time = time.time()\n",
        "    print(f\" Procesando {len(image_paths)} imágenes con {num_workers} hilos...\")\n",
        "\n",
        "    with tqdm(total=len(image_paths), desc=\"Procesando imágenes\", unit=\"img\", dynamic_ncols=True) as pbar:\n",
        "        with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
        "            results = list(executor.map(lambda p: process_image(*p), image_paths))\n",
        "            pbar.update(len(results))\n",
        "\n",
        "    # Registrar imágenes fallidas\n",
        "    failed_images = [image_paths[i][0] for i, success in enumerate(results) if not success]\n",
        "    print(f\"\\n Procesamiento completado en {time.time() - start_time:.2f} segundos.\")\n",
        "    print(f\" Total de imágenes procesadas: {len(image_paths) - len(failed_images)}\")\n",
        "    print(f\" Total de imágenes fallidas: {len(failed_images)}\")\n",
        "\n",
        "    if failed_images:\n",
        "        print(\"❌ Imágenes corruptas que no fueron agregadas:\")\n",
        "        for img in failed_images:\n",
        "            print(img)\n",
        "\n",
        "# Directorios de entrada y salida en Google Drive en Windows\n",
        "input_directory = os.path.join(base_drive_path, \"MURA-v1.1\")\n",
        "output_directory = os.path.join(base_drive_path, \"MURA_UC\")  # Nueva carpeta para guardar imágenes procesadas\n",
        "\n",
        "# Procesar imágenes en paralelo con 8 hilos\n",
        "tqdm.write(\" Iniciando el procesamiento de imágenes...\")\n",
        "process_images_parallel(input_directory, output_directory, num_workers=8)\n",
        "tqdm.write(\" Procesamiento completado!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0a7b023-9215-40c8-a5a8-4a5f92a698ad",
      "metadata": {
        "id": "e0a7b023-9215-40c8-a5a8-4a5f92a698ad"
      },
      "source": [
        "**DIVIDIR 80 Y 20% DATOS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1c4fa77-3f1b-4983-9cf7-e11bfda185f1",
      "metadata": {
        "id": "d1c4fa77-3f1b-4983-9cf7-e11bfda185f1",
        "outputId": "019f694a-53f5-4e61-b4af-f15369bede80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ División completada. CSVs generados en G:/Mi unidad/TESIS/MURA_UCD\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Ruta del dataset original (usaremos tanto train como valid)\n",
        "ruta_base = \"G:/Mi unidad/TESIS/MURA_UC\"\n",
        "ruta_original_train = os.path.join(ruta_base, \"train\")\n",
        "ruta_original_valid = os.path.join(ruta_base, \"valid\")  # Se incluirá en la división\n",
        "\n",
        "# Nueva carpeta donde se almacenará la división\n",
        "ruta_nueva_base = \"G:/Mi unidad/TESIS/MURA_UCD\"\n",
        "ruta_nueva_train = os.path.join(ruta_nueva_base, \"train\")\n",
        "ruta_nueva_valid = os.path.join(ruta_nueva_base, \"valid\")\n",
        "\n",
        "# Crear las nuevas carpetas si no existen\n",
        "os.makedirs(ruta_nueva_train, exist_ok=True)\n",
        "os.makedirs(ruta_nueva_valid, exist_ok=True)\n",
        "\n",
        "# Listas para almacenar las rutas y etiquetas\n",
        "datos = []  # Lista general para las imágenes\n",
        "\n",
        "# Función para recopilar imágenes de ambas carpetas\n",
        "def recopilar_imagenes(ruta_base):\n",
        "    imagenes = []\n",
        "    if os.path.isdir(ruta_base):\n",
        "        for tipo in os.listdir(ruta_base):  # Recorrer XR_ELBOW, XR_FINGER, etc.\n",
        "            ruta_tipo = os.path.join(ruta_base, tipo)\n",
        "            if os.path.isdir(ruta_tipo):\n",
        "                for paciente in os.listdir(ruta_tipo):  # Recorrer patient0001, patient0002, etc.\n",
        "                    ruta_paciente = os.path.join(ruta_tipo, paciente)\n",
        "                    if os.path.isdir(ruta_paciente):\n",
        "                        for estudio in os.listdir(ruta_paciente):  # Recorrer study1_negative, study2_positive, etc.\n",
        "                            ruta_estudio = os.path.join(ruta_paciente, estudio)\n",
        "                            if os.path.isdir(ruta_estudio):\n",
        "                                for img in os.listdir(ruta_estudio):  # Listar imágenes\n",
        "                                    img_path = os.path.join(ruta_estudio, img)\n",
        "                                    etiqueta = 0 if \"negative\" in estudio.lower() else 1  # Etiqueta 0 o 1\n",
        "                                    imagenes.append((img_path, etiqueta, tipo, paciente, estudio))\n",
        "    return imagenes\n",
        "\n",
        "# Recopilar imágenes de ambas carpetas\n",
        "imagenes_total = recopilar_imagenes(ruta_original_train) + recopilar_imagenes(ruta_original_valid)\n",
        "\n",
        "# Mezclar imágenes aleatoriamente\n",
        "random.shuffle(imagenes_total)\n",
        "\n",
        "# Calcular la cantidad exacta para train y valid\n",
        "num_train = int(len(imagenes_total) * 0.8)\n",
        "imagenes_train = imagenes_total[:num_train]\n",
        "imagenes_valid = imagenes_total[num_train:]\n",
        "\n",
        "# Copiar imágenes y crear CSV\n",
        "datos_train, datos_valid = [], []\n",
        "\n",
        "for img_path, etiqueta, tipo, paciente, estudio in imagenes_train:\n",
        "    ruta_tipo_train = os.path.join(ruta_nueva_train, tipo)\n",
        "    ruta_paciente_train = os.path.join(ruta_tipo_train, paciente)\n",
        "    ruta_estudio_train = os.path.join(ruta_paciente_train, estudio)\n",
        "    os.makedirs(ruta_estudio_train, exist_ok=True)\n",
        "    nueva_ruta = os.path.join(ruta_estudio_train, os.path.basename(img_path))\n",
        "\n",
        "    try:\n",
        "        shutil.copy(img_path, nueva_ruta)\n",
        "        datos_train.append([nueva_ruta, etiqueta])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al copiar {img_path}: {e}\")\n",
        "\n",
        "for img_path, etiqueta, tipo, paciente, estudio in imagenes_valid:\n",
        "    ruta_tipo_valid = os.path.join(ruta_nueva_valid, tipo)\n",
        "    ruta_paciente_valid = os.path.join(ruta_tipo_valid, paciente)\n",
        "    ruta_estudio_valid = os.path.join(ruta_paciente_valid, estudio)\n",
        "    os.makedirs(ruta_estudio_valid, exist_ok=True)\n",
        "    nueva_ruta = os.path.join(ruta_estudio_valid, os.path.basename(img_path))\n",
        "\n",
        "    try:\n",
        "        shutil.copy(img_path, nueva_ruta)\n",
        "        datos_valid.append([nueva_ruta, etiqueta])\n",
        "    except Exception as e:\n",
        "        print(f\"Error al copiar {img_path}: {e}\")\n",
        "\n",
        "# Guardar los CSV\n",
        "df_train = pd.DataFrame(datos_train, columns=[\"ruta\", \"etiqueta\"])\n",
        "df_valid = pd.DataFrame(datos_valid, columns=[\"ruta\", \"etiqueta\"])\n",
        "\n",
        "df_train.to_csv(os.path.join(ruta_nueva_base, \"train.csv\"), index=False)\n",
        "df_valid.to_csv(os.path.join(ruta_nueva_base, \"valid.csv\"), index=False)\n",
        "\n",
        "print(f\"✅ División completada. CSVs generados en {ruta_nueva_base}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52249676-53c3-4ec3-a950-a733cc00e935",
      "metadata": {
        "id": "52249676-53c3-4ec3-a950-a733cc00e935"
      },
      "source": [
        "**CONTAR CANRIDAD DE IMAGENES DESPUES DE DIVISION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32767009-f0b6-484f-9be0-89de74441c50",
      "metadata": {
        "id": "32767009-f0b6-484f-9be0-89de74441c50",
        "outputId": "0ffba283-d3e1-4186-e54b-2e45184bc380"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de imágenes en TRAIN: 32004\n",
            "Total de imágenes en VALID: 8001\n",
            "Total de imágenes en el dataset dividido: 40005\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Ruta a la carpeta nueva donde se dividieron las imágenes\n",
        "ruta_nueva_base = \"G:/Mi unidad/TESIS/MURA_UCD\"\n",
        "ruta_train = os.path.join(ruta_nueva_base, \"train\")\n",
        "ruta_valid = os.path.join(ruta_nueva_base, \"valid\")\n",
        "\n",
        "# Función para contar imágenes en una carpeta\n",
        "def contar_imagenes(ruta_base):\n",
        "    total_imagenes = 0\n",
        "    for tipo in os.listdir(ruta_base):  # Recorrer XR_ELBOW, XR_FINGER, etc.\n",
        "        ruta_tipo = os.path.join(ruta_base, tipo)\n",
        "        if os.path.isdir(ruta_tipo):\n",
        "            for paciente in os.listdir(ruta_tipo):  # Recorrer patient0001, patient0002, etc.\n",
        "                ruta_paciente = os.path.join(ruta_tipo, paciente)\n",
        "                if os.path.isdir(ruta_paciente):\n",
        "                    for estudio in os.listdir(ruta_paciente):  # Recorrer study1_negative, study2_positive, etc.\n",
        "                        ruta_estudio = os.path.join(ruta_paciente, estudio)\n",
        "                        if os.path.isdir(ruta_estudio):\n",
        "                            total_imagenes += len(os.listdir(ruta_estudio))  # Contar archivos en cada estudio\n",
        "    return total_imagenes\n",
        "\n",
        "# Contar imágenes en train y valid\n",
        "total_train = contar_imagenes(ruta_train)\n",
        "total_valid = contar_imagenes(ruta_valid)\n",
        "\n",
        "# Mostrar resultados\n",
        "print(f\"Total de imágenes en TRAIN: {total_train}\")\n",
        "print(f\"Total de imágenes en VALID: {total_valid}\")\n",
        "\n",
        "# Verificar que la suma sea 40,005\n",
        "total_general = total_train + total_valid\n",
        "print(f\"Total de imágenes en el dataset dividido: {total_general}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6698e2e4-b2e6-4149-b214-dbfa1750007b",
      "metadata": {
        "id": "6698e2e4-b2e6-4149-b214-dbfa1750007b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}