{"cells":[{"cell_type":"markdown","id":"973b3113-4893-460c-bef2-05bd5659e648","metadata":{"id":"973b3113-4893-460c-bef2-05bd5659e648"},"source":["**ENTRENAMIENTO**"]},{"cell_type":"code","execution_count":null,"id":"56088f2b-bbb7-4639-9b92-9b21a421a71b","metadata":{"scrolled":true,"id":"56088f2b-bbb7-4639-9b92-9b21a421a71b","outputId":"3d053f25-2699-4eb5-c3d0-af361a173b0d"},"outputs":[{"name":"stdout","output_type":"stream","text":["âœ… Usando cuda\n"," dataset_pt/train_UCD ya tiene 5 archivos .pt. No se convierte de nuevo.\n"," dataset_pt/valid_UCD ya tiene 2 archivos .pt. No se convierte de nuevo.\n","âœ… Pesos de clase: tensor([0.6366, 0.6456, 0.8933, 1.2893, 0.8371, 1.2857, 2.2023, 3.4428, 0.6729,\n","        1.6971, 3.5387, 3.8812, 0.4675, 0.6607], device='cuda:0')\n","Loaded pretrained weights for efficientnet-b4\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_2020\\1050083405.py:190: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = torch.cuda.amp.GradScaler()\n","C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_2020\\1050083405.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(path, map_location=device)\n"]},{"name":"stdout","output_type":"stream","text":[" Checkpoint cargado desde epoch 50\n","Iniciando entrenamiento\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_2020\\1050083405.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  data = torch.load(pt_file)\n","F2 Epoch 51 - batch_0.pt:   0%|                                                                | 0/625 [00:00<?, ?it/s]C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_2020\\1050083405.py:222: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():\n","F2 Epoch 51 - batch_0.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:13<00:00,  8.46it/s, acc=0.874, loss=0.281]\n","F2 Epoch 51 - batch_1.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:12<00:00,  8.57it/s, acc=0.875, loss=0.279]\n","F2 Epoch 51 - batch_2.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:08<00:00,  9.12it/s, acc=0.873, loss=0.279]\n","F2 Epoch 51 - batch_3.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:09<00:00,  9.03it/s, acc=0.875, loss=0.276]\n","F2 Epoch 51 - batch_4.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:10<00:00,  8.88it/s, acc=0.876, loss=0.272]\n"]},{"name":"stdout","output_type":"stream","text":[" Checkpoint guardado en epoch 50\n"]},{"name":"stderr","output_type":"stream","text":["F2 Epoch 52 - batch_0.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:10<00:00,  8.84it/s, acc=0.876, loss=0.275]\n","F2 Epoch 52 - batch_1.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:09<00:00,  8.97it/s, acc=0.876, loss=0.265]\n","F2 Epoch 52 - batch_2.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:13<00:00,  8.48it/s, acc=0.875, loss=0.266]\n","F2 Epoch 52 - batch_3.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:09<00:00,  9.01it/s, acc=0.878, loss=0.263]\n","F2 Epoch 52 - batch_4.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:10<00:00,  8.91it/s, acc=0.88, loss=0.259]\n"]},{"name":"stdout","output_type":"stream","text":[" Checkpoint guardado en epoch 51\n"]},{"name":"stderr","output_type":"stream","text":["F2 Epoch 53 - batch_0.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:08<00:00,  9.07it/s, acc=0.87, loss=0.272]\n","F2 Epoch 53 - batch_1.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:13<00:00,  8.53it/s, acc=0.872, loss=0.268]\n","F2 Epoch 53 - batch_2.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:11<00:00,  8.75it/s, acc=0.872, loss=0.271]\n","F2 Epoch 53 - batch_3.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:11<00:00,  8.80it/s, acc=0.874, loss=0.269]\n","F2 Epoch 53 - batch_4.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:08<00:00,  9.06it/s, acc=0.874, loss=0.268]\n"]},{"name":"stdout","output_type":"stream","text":[" Checkpoint guardado en epoch 52\n"]},{"name":"stderr","output_type":"stream","text":["F2 Epoch 54 - batch_0.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:13<00:00,  8.52it/s, acc=0.882, loss=0.273]\n","F2 Epoch 54 - batch_1.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:09<00:00,  8.94it/s, acc=0.88, loss=0.265]\n","F2 Epoch 54 - batch_2.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:10<00:00,  8.91it/s, acc=0.881, loss=0.261]\n","F2 Epoch 54 - batch_3.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:10<00:00,  8.91it/s, acc=0.879, loss=0.261]\n","F2 Epoch 54 - batch_4.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:09<00:00,  9.03it/s, acc=0.881, loss=0.258]\n"]},{"name":"stdout","output_type":"stream","text":[" Checkpoint guardado en epoch 53\n"]},{"name":"stderr","output_type":"stream","text":["F2 Epoch 55 - batch_0.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:09<00:00,  9.04it/s, acc=0.879, loss=0.26]\n","F2 Epoch 55 - batch_1.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:10<00:00,  8.93it/s, acc=0.879, loss=0.258]\n","F2 Epoch 55 - batch_2.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:10<00:00,  8.83it/s, acc=0.877, loss=0.262]\n","F2 Epoch 55 - batch_3.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:10<00:00,  8.91it/s, acc=0.877, loss=0.263]\n","F2 Epoch 55 - batch_4.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [01:09<00:00,  8.98it/s, acc=0.88, loss=0.26]\n"]},{"name":"stdout","output_type":"stream","text":[" Checkpoint guardado en epoch 54\n","âœ… Modelo final guardado como efficientnet_multiclaseUCD.pth\n"]}],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.io as io\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from sklearn.utils.class_weight import compute_class_weight\n","from efficientnet_pytorch import EfficientNet\n","import glob\n","from torchvision.io import read_image\n","import gc\n","import kornia.augmentation as K\n","\n","# ===============================\n","# ConfiguraciÃ³n\n","# ===============================\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"âœ… Usando {device}\")\n","\n","transform_gpu = nn.Sequential(\n","    K.RandomHorizontalFlip(p=0.5),\n","    K.RandomRotation(degrees=30.0),\n","    K.RandomBrightness(0.2),\n","    K.Normalize(mean=torch.tensor([0.5]*3), std=torch.tensor([0.5]*3))\n",").to(device)\n","\n","\n","NUM_CLASSES = 14\n","BATCH_SIZE = 8\n","EPOCHS_FROZEN = 30\n","EPOCHS_UNFROZEN = 25\n","LR_FROZEN = 1e-3\n","LR_UNFROZEN = 1e-5\n","IMG_SIZE = 384\n","\n","\n","def convertir_csv_a_pt(csv_path, output_dir, batch_size=5000):\n","    os.makedirs(output_dir, exist_ok=True)\n","    df = pd.read_csv(csv_path)\n","    images, labels = [], []\n","\n","    for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Procesando {os.path.basename(csv_path)}\"):\n","        ruta = row[\"ruta\"]\n","        clase = int(row[\"clase\"])\n","        preprocess = transforms.Compose([\n","            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","            transforms.ConvertImageDtype(torch.float32),\n","            transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n","        ])\n","\n","        img = read_image(ruta)\n","        if img.shape[0] == 1:\n","            img = img.repeat(3, 1, 1)\n","        img = preprocess(img)\n","        images.append(img)\n","        labels.append(clase)\n","\n","        if len(images) == batch_size or idx == len(df) - 1:\n","            batch_id = idx // batch_size\n","            torch.save({\n","                \"images\": torch.stack(images),\n","                \"labels\": torch.tensor(labels, dtype=torch.long)\n","            }, os.path.join(output_dir, f\"batch_{batch_id}.pt\"))\n","            print(f\"âœ… Guardado {output_dir}/batch_{batch_id}.pt\")\n","            images, labels = [], []\n","            torch.cuda.empty_cache()\n","            gc.collect()\n","\n","def verificar_o_convertir(csv_path, output_dir):\n","    archivos = glob.glob(os.path.join(output_dir, \"*.pt\"))\n","    if len(archivos) > 0:\n","        print(f\" {output_dir} ya tiene {len(archivos)} archivos .pt. No se convierte de nuevo.\")\n","    else:\n","        print(f\" No hay archivos .pt en {output_dir}. Se crearÃ¡n a partir del CSV.\")\n","        convertir_csv_a_pt(csv_path, output_dir)\n","\n","\n","# ===============================\n","# Transformaciones\n","# ===============================\n","def get_transforms(train=True):\n","    if train:\n","        return A.Compose([\n","            A.Rotate(limit=30),\n","            A.HorizontalFlip(),\n","            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15),\n","            A.RandomBrightnessContrast(),\n","            A.Normalize(mean=(0.5,), std=(0.5,)),\n","            ToTensorV2(),\n","        ])\n","    else:\n","        return A.Compose([\n","            A.Normalize(mean=(0.5,), std=(0.5,)),\n","            ToTensorV2(),\n","        ])\n","\n","\n","# ===============================\n","# Dataset desde CSV\n","# ===============================\n","class PTBatchDataset(torch.utils.data.Dataset):\n","    def __init__(self, pt_file, transform=None):\n","        data = torch.load(pt_file)\n","        self.images = data[\"images\"]\n","        self.labels = data[\"labels\"]\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        x = self.images[idx].to(device)\n","        y = self.labels[idx].to(device)\n","\n","        if self.transform:\n","            x = self.transform(x.unsqueeze(0)).squeeze(0)\n","\n","        return x, y\n","\n","\n","\n","\n","# Funciones para checkpoint\n","def save_checkpoint(model, optimizer, epoch, path=\"checkpoint_efficientnetUCD.pth\"):\n","    torch.save({\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict()\n","    }, path)\n","    print(f\" Checkpoint guardado en epoch {epoch}\")\n","\n","def load_checkpoint(model, optimizer, path=\"checkpoint_efficientnetUCD.pth\"):\n","    if os.path.exists(path):\n","        checkpoint = torch.load(path, map_location=device)\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        print(f\" Checkpoint cargado desde epoch {checkpoint['epoch'] + 1}\")\n","        return checkpoint['epoch'] + 1\n","    print(\" No se encontrÃ³ checkpoint. Empezando desde 0.\")\n","    return 0\n","\n","\n","# ===============================\n","# Datos y loaders\n","# ===============================\n","train_csv = \"D:/Mi unidad/TESIS/MURA_UCD/train_multiclase_corr.csv\"\n","valid_csv = \"D:/Mi unidad/TESIS/MURA_UCD/valid_multiclase_corr.csv\"\n","\n","verificar_o_convertir(train_csv, \"dataset_pt/train_UCD\")\n","verificar_o_convertir(valid_csv, \"dataset_pt/valid_UCD\")\n","\n","train_pt_files = sorted(glob.glob(\"dataset_pt/train_UCD/*.pt\"))\n","valid_pt_files = sorted(glob.glob(\"dataset_pt/valid_UCD/*.pt\"))\n","\n","\n","\n","\n","# ===============================\n","#  Pesos de clase\n","# ===============================\n","y_train = pd.read_csv(train_csv)[\"clase\"].values\n","class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n","weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n","print(\"âœ… Pesos de clase:\", weights_tensor)\n","\n","# ===============================\n","#  Modelo EfficientNetB4\n","# ===============================\n","model = EfficientNet.from_pretrained(\"efficientnet-b4\", num_classes=NUM_CLASSES)\n","model = model.to(device)\n","\n","# Congelar todas menos Ãºltimas capas\n","for param in model.parameters():\n","    param.requires_grad = False\n","for param in model._fc.parameters():\n","    param.requires_grad = True\n","\n","# ===============================\n","# Fase 1: capas congeladas\n","# ===============================\n","# InicializaciÃ³n para fase 1\n","optimizer = torch.optim.Adam(model.parameters(), lr=LR_FROZEN)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.2)\n","criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n","scaler = torch.cuda.amp.GradScaler()\n","\n","start_epoch = load_checkpoint(model, optimizer)\n","\n","# ===============================\n","# Entrenamiento por archivo .pt\n","# ===============================\n","print(\"Iniciando entrenamiento\")\n","\n","for epoch in range(start_epoch, EPOCHS_FROZEN + EPOCHS_UNFROZEN):\n","\n","    if epoch == EPOCHS_FROZEN:\n","        print(\"Fase 2: Fine-tuning completo\")\n","        for param in model.parameters():\n","            param.requires_grad = True\n","        optimizer = torch.optim.Adam(model.parameters(), lr=LR_UNFROZEN)\n","        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.2)\n","\n","    model.train()\n","    correct, total, loss_acum = 0, 0, 0\n","    fase = \"F1\" if epoch < EPOCHS_FROZEN else \"F2\"\n","\n","    for pt_file in train_pt_files:\n","        dataset = PTBatchDataset(pt_file, transform=transform_gpu)\n","\n","\n","        train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","        loop = tqdm(train_loader, desc=f\"{fase} Epoch {epoch+1} - {os.path.basename(pt_file)}\")\n","\n","        for images, labels in loop:\n","            optimizer.zero_grad()\n","            with torch.cuda.amp.autocast():\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","\n","            preds = torch.argmax(outputs, dim=1)\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","            loss_acum += loss.item()\n","            loop.set_postfix(loss=loss_acum / (total / BATCH_SIZE), acc=correct / total)\n","\n","        #  Liberar memoria por archivo\n","        del dataset, train_loader, images, labels, outputs, preds\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","    scheduler.step(loss_acum / (total / BATCH_SIZE))\n","    save_checkpoint(model, optimizer, epoch)\n","\n","\n","# ===============================\n","# Guardar modelo final\n","# ===============================\n","torch.save(model.state_dict(), \"efficientnet_multiclaseUCD.pth\")\n","print(\"âœ… Modelo final guardado como efficientnet_multiclaseUCD.pth\")\n"]},{"cell_type":"markdown","id":"8f84730b-eeb5-4a81-87d7-ca4fdfa04cd3","metadata":{"id":"8f84730b-eeb5-4a81-87d7-ca4fdfa04cd3"},"source":["**PREDICCIONES**"]},{"cell_type":"markdown","id":"89655b2c-a995-4887-9136-56fc84987b77","metadata":{"id":"89655b2c-a995-4887-9136-56fc84987b77"},"source":["**CURVA DE ROC POR CLASES Y AUC**"]},{"cell_type":"code","execution_count":null,"id":"f22236c7-f5fe-4768-b4a3-54467c4025c3","metadata":{"id":"f22236c7-f5fe-4768-b4a3-54467c4025c3","outputId":"fcaaf3c3-0e35-4f7e-a66e-fb6f877cf942"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_2020\\1965974550.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  data = torch.load(pt_file)\n"]},{"name":"stdout","output_type":"stream","text":["ðŸ“Š Reporte de ClasificaciÃ³n:\n","\n","              precision    recall  f1-score   support\n","\n","     Clase 0      0.734     0.867     0.795       905\n","     Clase 1      0.834     0.687     0.753       905\n","     Clase 2      0.810     0.892     0.849       601\n","     Clase 3      0.843     0.728     0.781       463\n","     Clase 4      0.755     0.902     0.822       621\n","     Clase 5      0.824     0.588     0.686       437\n","     Clase 6      0.812     0.924     0.864       276\n","     Clase 7      0.805     0.642     0.714       148\n","     Clase 8      0.848     0.840     0.844       933\n","     Clase 9      0.572     0.607     0.589       326\n","    Clase 10      0.791     0.863     0.825       175\n","    Clase 11      0.857     0.680     0.758       150\n","    Clase 12      0.830     0.915     0.870      1239\n","    Clase 13      0.866     0.726     0.790       822\n","\n","    accuracy                          0.802      8001\n","   macro avg      0.798     0.776     0.782      8001\n","weighted avg      0.806     0.802     0.799      8001\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","from torch.utils.data import TensorDataset\n","\n","all_preds = []\n","all_labels = []\n","\n","model.eval()\n","with torch.no_grad():\n","    for pt_file in valid_pt_files:  # <--- CORREGIDO\n","        data = torch.load(pt_file)\n","        X = data[\"images\"]\n","        y = data[\"labels\"]\n","        val_loader = DataLoader(TensorDataset(X, y), batch_size=BATCH_SIZE, shuffle=False)\n","\n","        for images, labels in val_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(images)\n","            preds = torch.argmax(outputs, dim=1)\n","\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","        del data, X, y, val_loader\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","# ===============================\n","# Reporte de clasificaciÃ³n\n","# ===============================\n","target_names = [f\"Clase {i}\" for i in range(NUM_CLASSES)]\n","reporte = classification_report(all_labels, all_preds, target_names=target_names, digits=3)\n","print(\"ðŸ“Š Reporte de ClasificaciÃ³n:\\n\")\n","print(reporte)\n"]},{"cell_type":"code","execution_count":null,"id":"ec60810f-75eb-4e7f-b32b-2bf8bd7f16df","metadata":{"id":"ec60810f-75eb-4e7f-b32b-2bf8bd7f16df","outputId":"f0a835fc-7aef-4e1a-c494-f3adc66e4b1f"},"outputs":[{"name":"stdout","output_type":"stream","text":["âœ… Curva ROC guardada para Clase 0\n","âœ… Curva ROC guardada para Clase 1\n","âœ… Curva ROC guardada para Clase 2\n","âœ… Curva ROC guardada para Clase 3\n","âœ… Curva ROC guardada para Clase 4\n","âœ… Curva ROC guardada para Clase 5\n","âœ… Curva ROC guardada para Clase 6\n","âœ… Curva ROC guardada para Clase 7\n","âœ… Curva ROC guardada para Clase 8\n","âœ… Curva ROC guardada para Clase 9\n","âœ… Curva ROC guardada para Clase 10\n","âœ… Curva ROC guardada para Clase 11\n","âœ… Curva ROC guardada para Clase 12\n","âœ… Curva ROC guardada para Clase 13\n"]}],"source":["# Convertir etiquetas a one-hot\n","y_true = label_binarize(all_labels, classes=list(range(NUM_CLASSES)))\n","y_score = all_probs  # ya es (N, 14)\n","\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","\n","os.makedirs(\"roc_por_clase\", exist_ok=True)\n","\n","for i in range(NUM_CLASSES):\n","    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_score[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","    # Plot\n","    plt.figure(figsize=(6, 5))\n","    plt.plot(fpr[i], tpr[i], color='blue', lw=2, label=f\"AUC = {roc_auc[i]:.2f}\")\n","    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel(\"Falsos Positivos\")\n","    plt.ylabel(\"Verdaderos Positivos\")\n","    plt.title(f\"Curva ROC - Clase {i}\")\n","    plt.legend(loc=\"lower right\")\n","    plt.grid(True)\n","    plt.tight_layout()\n","    plt.savefig(f\"roc_por_clase/roc_clase_{i}.png\")\n","    plt.close()\n","    print(f\"âœ… Curva ROC guardada para Clase {i}\")\n"]},{"cell_type":"code","execution_count":null,"id":"bc30d295-794a-4bf7-9032-9776d19ea396","metadata":{"id":"bc30d295-794a-4bf7-9032-9776d19ea396","outputId":"82c8b245-c0bf-49d9-da08-ff33aa7c1958"},"outputs":[{"name":"stdout","output_type":"stream","text":["âœ… Matriz de confusiÃ³n guardada como matriz_confusion.png\n"]}],"source":["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# ===============================\n","# Predicciones finales por clase\n","# ===============================\n","y_true = all_labels\n","y_pred = np.argmax(all_probs, axis=1)\n","\n","# ===============================\n","# Matriz de confusiÃ³n\n","# ===============================\n","cm = confusion_matrix(y_true, y_pred)\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n","            xticklabels=[f\"C{i}\" for i in range(NUM_CLASSES)],\n","            yticklabels=[f\"C{i}\" for i in range(NUM_CLASSES)])\n","plt.xlabel(\"PredicciÃ³n\")\n","plt.ylabel(\"Valor real\")\n","plt.title(\"Matriz de ConfusiÃ³n - ValidaciÃ³n\")\n","plt.tight_layout()\n","plt.savefig(\"matriz_confusion.png\")\n","plt.close()\n","print(\"âœ… Matriz de confusiÃ³n guardada como matriz_confusion.png\")\n"]},{"cell_type":"code","execution_count":null,"id":"af1e32c0-799c-48c2-85f5-6f1a054d432c","metadata":{"id":"af1e32c0-799c-48c2-85f5-6f1a054d432c"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}